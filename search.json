[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ising book",
    "section": "",
    "text": "A feature of statistical mechanics post WWII is that it sacrifices perfect modeling of physical reality for mathematical rigor, as the minutiae of atomic interactions is unknown; which is why we can accurately model physical reality using probabilistic systems.\nweiss proposes that magnetic materials consist of micromagnets placed in regular array, but wilhelm lenz believes they can point in one of two directions. ising calculated the model for a 1d system by assuming that only nearest-neighbor interactions between the micro magnets.\ninitially the model was dismissed because it was incompatible with heisenbergs theory of ferromagnetism, but was shown in 1936 by peierls to exhibit ferromagnetism in 2 dimensions\nPhysics preliminaries:\n\nmathematical structure that can represent a variety of physical phenomena\nmodel is a lattice with each particle assigned to a lattice site\nparticle has intrinsic angular momentum (\\(\\sigma\\))\n(up or down)\n$$ \\sum_{i=1}^n x_i $$\n\\[\\Sigma\\]\n\n\n\\[\\begin{equation}\\]\nE=-J \\sum_{i, j=n n(i)}^N s_i s_j-H \\sum_{i=1}^N s_i\n\\[E=-J \\sum_{i, j=n n(i)}^N s_i s_j-H \\sum_{i=1}^N s_i\\]\nTheories prior to ising :\n\n1831 michael farady presents paper on electromagnetism to the british royal society. he created a conducting disk which uses a magnet to generate an electric current.\n1860s - James Clerk Maxwell introduces concept of ensemble to understand statistical mechanics of gasses. group of systems considered to be equivalent (NVT - same # of atoms, same volume, same temperature) systems have microstates, specific configurations a system can occupy within probability of its fluctuations. ex temp of system, temp is an average, but actual atoms can be in different places of the entire system. microstates are distinct arrangements.\n\n\n\n1870s - boltzmann wants to understand the behavior of gases in terms of the motion and interactions of atoms and molecules, prior to this they were explained by macroscopic models.\n\n“the behavior of a macroscopic system can be understood in terms of the statistical distribution of the energy levels of its microscopic particles” where the distribution is determined by the temperature of the system (which is a measure of average kinetic energy)\nentropy - measure of disorder (randomness) of system - tends to increase over time.\nstatistical approach allows us to predict the behavior of a system based on the average number of particles, rather than trying to track each particle.\nentropy mattered as the temperature of the gas increased, the kinetic energy of the molecules increases, leading to more disordered configurations.\nimplies that at lower levels the system becomes more ordered\nNVT CANONICAL- boltzmann updates nvt based on idea of “heat bath”. introduces partition function and boltzmann distribution to understand thermodynamics of gaes and other systems in equilibrium with a heat bath at a constant temperature.\nheat bath is a larger system that transfers heat with the system of study\nboltzmann distribution explains the probability of a given microstate of the system:\n\\[\nP(E) = (1/Z) * exp(-E/k_B T)\n\\]\n\\[\nZ = \\Sigma(exp(-E/k_B T))\n\\]\nz = partition function, sums over all potential configurations of energy of system.\n“boltzmann function over all possible energy states of system”\npartition function calculates probability of a system being in a particular energy state as a function of temperature, gibbs sampler is probability of system being in particular energy state and a particular set of other variables.\ncalled partition b/c it encodes how probabilities are partitioned among different microstates.\n\n\n\n\n1895 - pierre curie defines 3 classes of magnetic substances:\n\ndiamagnetic - not magnetic because they dont have unpaired electrons\nferromagnetic - strong tendency to become magnetized even in the absence of an external magnetic field because their spins tend to align with each other- but have a critical temperature (curie temp) which above this temp the material becomes paramagnetic because heat means the particles are all in different directions\nparamagnetic - unpaired electons and magnetic moment, but moment is weak and they tend not to align with eachother\nnet magnetic moment - measure of tendency to align with a magnetic field “strength and orientation of a magnetic object” (vector quantity)\nCurie Law - magnetic susceptibility of a paramagnetic substance varies inversely with absolute temperature\n\n1852 - wilhelm weber creates model based on idea that magnetic matter consists of “tiny magnetic needles” representing an atom/molecule with their own magnetic moment.\n1905 - Paul Langevin (curies student) applies boltzmanns statistical ideas to the field of magnetism\n\ndetermines the intensity of magnetization by applying boltzmanns theory to a gas of molecules\n\n1920 (~) general agreement that magnetic materials consist of elementary micromagnets, boltzmann statistical formalism is the right tool to describe theoretically.\n\nPierre weiss’s idea of lattice array doesn’t yet include ability to point in two directions\nLenz shares work showing that curies law underpins the laws of paramagnetism, and believes that para and ferro magnetism are fundamentally connected.\nidea was that up until that point- magnetism was thought to be something that followed a crystal structure, which could explain some phenomena, but not all. Giving the atomic magnets ability to rotate couldn’t work with solid objects, but what he found via experimentation on the crystal structure of pyrrhotite (which exhibits a hexagonal structure). it was not possible to change the magnetization of a sample much by applying an external field, but he noticed that he could change the orientation of the magnetization\n\n1925 ising does the calculations for lenz’s model as his phd thesis (but incorrectly generalizes his assumptions about 1d model to 2/3d)\nso we have farady explaining electromagnetism, boltzmann and curie creating the physical laws which will underpin the properties of ferromagnetism, langevin and weiss laying the groundwork for the theory, lenz coming up with a model from theory and experiment, and ising finalizing the calculations."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "4  Conclusion",
    "section": "",
    "text": "The 1D Ising model is a special case of the 2D Ising model, where the lattice of spins is a one-dimensional chain rather than a two-dimensional grid. Both models have been widely used to study the behavior of ferromagnetic materials and to understand the mechanisms behind phase transitions.\nOne way to simulate the behavior of these models is through the use of Markov chain Monte Carlo (MCMC) algorithms, such as the Metropolis-Hastings algorithm and the Gibbs sampler. The Metropolis-Hastings algorithm is a widely used MCMC algorithm that generates samples from a target distribution by making random moves and accepting or rejecting them based on the acceptance probability.\nThe Gibbs sampler is another MCMC algorithm that can be used to generate samples from a target distribution. The Gibbs sampler works by sampling from the full conditional distributions of the variables in the target distribution, rather than making random moves and accepting or rejecting them. This approach has several advantages over the Metropolis-Hastings algorithm, including faster convergence and the ability to sample from multi-dimensional distributions.\nIn conclusion, the 1D and 2D Ising models are important mathematical models that were developed to describe the behavior of ferromagnetic materials and have been widely used to study phase transitions in other systems. The Gibbs sampler is a powerful tool for simulating these models and studying their behavior, and offers several advantages over the more commonly used Metropolis-Hastings algorithm."
  },
  {
    "objectID": "the_first_dimension.html",
    "href": "the_first_dimension.html",
    "title": "1  The Ising Model in One Dimension",
    "section": "",
    "text": "A Linear Chain\n\n\nOriginally, the 1d model was used as a theoretical tool- a base case to begin exploration of magnetic systems in statistical mechanics. It is not supposed to represent any physical system, though it had been used to that effect in modern times.\n\\[\nE=-J \\sum_{i, j=n n(i)}^N s_i s_j-H \\sum_{i=1}^N s_i\n\\]\nHere we have what is called the Hamiltonian for the model. A Hamiltonian (named after William Hamilton) is a function which describes the total energy of a physical system. It does this by giving us the sum of the products (interactions) between the particles of the system as well as the sum of the interactions between those individual particles as well as any external field that may be interacting with the system. This can be thought of more briefly as the kinetic energy of the particles and the potential energy of the system. Oftentimes we study the system as having no external field, so the second term is set to zero, leaving us with just the first:\n\\[\nE=-J \\sum_{i, j=n n(i)}^N s_i s_j\n\\]\nFrom Boltzmann we know that the probability of finding a particular spin configuration is the proportion of that configuration over the sum of all possible configurations:\n$$ p({s_i})=1/Z * exp(-E({s_i})),\n\\[ \\]\n / K_BT,\n\\[ \\]\nZ = _{i} exp(-E_j) $$\nNote the indices under the summation of the partition function as well as the hamiltonian- there is one for each. The trick to keep in mind there is that you are not just summing over each particle in the system but also every single potential energy state for that particle:\n\\[Z = \\sum_{s_1= \\pm 1} \\sum_{s_2 = \\pm 1} ... \\sum_{s_n \\pm 1} exp(-\\beta J (s_1s_2+s_2s_3+...)\\]\nTo simplify this expression, we introduce a new variable, \\[ \\mu_i := s_i * s_{i+1} \\], allowing us to rewrite the above equation as:\n\\[\nZ = 2 * \\sum_{\\mu} exp(\\beta J \\sum_{i=1}^N \\mu_{i})\n\\]\nwhere the two comes from the two possible configurations for the fist spin in the chain.\nThis value for Z allows us to enumerate all of the microstates the system can potentially take.\n\nexplain theoretical desire for 1d ising model, go through mathematical breakdown, build up explanation, give physical interpretation, explain how to get to transition matrices, set up 2d model."
  },
  {
    "objectID": "mhmc.html",
    "href": "mhmc.html",
    "title": "3  Metropolis Hastings Code",
    "section": "",
    "text": "# Monte Carlo simulation using the Metropolis-Hastings algorithm\ndef monte_carlo(spins, T):\n    # Iterate over the atoms in the system\n    for m in range(N):\n        for n in range(N):\n            # Choose a random atom\n            a = np.random.randint(0, N)\n            b = np.random.randint(0, N)\n\n            # Calculate the change in energy if the spin of the atom is flipped\n            delta_E = 2 * spins[a, b] * (spins[(a + 1) % N, b] + spins[a, (b + 1) % N] + spins[(a - 1) % N, b] + spins[a, (b - 1) % N])\n\n            # Use the Metropolis-Hastings algorithm to determine whether or not to flip the spin\n            if delta_E <= 0:\n                # If the change in energy is negative, flip the spin\n                spins[a, b] *= -1\n            elif np.exp(-delta_E / T) > np.random.rand():\n                # If the change in energy is positive, flip the spin with probability exp(-delta_E / T)\n                spins[a, b] *= -1\n\n    # Return the resulting spin array\n    return spins\n\n\nfig = plt.figure(figsize=(7, 7)) \nax = plt.subplot(111) \n\n# Set up the plot \nim = ax.imshow(spins, cmap=plt.cm.RdBu, vmin=-1, vmax=1, animated=True) \nplt.axis('off') \n\n# create a counter and add it to the plot\ncounter = ax.annotate('Step: 0', xy=(0.05, 0.95), xycoords='axes fraction', color='white')\n\n# Set up the function to update the plot \ndef update(frame): \n    global spins, counter \n    spins = monte_carlo(spins, T) \n    im.set_array(spins)\n\n    # update the step count on the plot\n    counter.set_text('Step: {}'.format(frame))\n    return [im, counter]\n    \n\nani = FuncAnimation(fig, update, frames=np.arange(0, 200000), interval=0, blit=True) \n'''ani.save('ising_model_animation.gif', fps=3)'''\n''''ani.save('animation.gif', writer='imagemagick')'''\nplt.show()"
  },
  {
    "objectID": "the_second_dimension.html",
    "href": "the_second_dimension.html",
    "title": "2  The Second Dimension",
    "section": "",
    "text": "\\[ E = -J \\sum_{ij} S_iS_j \\]\nWhere \\(J\\) is the coupling constant, which represents the strength of the interaction between spins, \\(S_i\\) and \\(S_j\\) are the values of the spins at positions \\(i\\) and \\(j\\), and the sum is taken over all pairs of spins on the lattice. The 2D Ising model can be used to study the behavior of ferromagnetic materials, where the spins are aligned and the system has a low energy, and the transition to an ordered state as the temperature is lowered. It has also been used to study phase transitions in other systems, such as the behavior of fluids and gases."
  }
]